{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 samples must be a = [state, action, rewards, next_state, is_done]\n",
    "# is_done is for determining a terminal or non-terminal state\n",
    "\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "class ReplayMemory:\n",
    "    main_memory = []\n",
    "    max_reply = 0\n",
    "    num_batch = 0\n",
    "    def __init__(self, max_replay: int, mini_batch_num: int):\n",
    "        self.max_reply = max_replay\n",
    "        self.num_batch = mini_batch_num\n",
    "\n",
    "class DeepQAgent:\n",
    "    replay:ReplayMemory = None\n",
    "    num_actions: int = None\n",
    "    eval_model = None\n",
    "    target_model = None\n",
    "    gamma:float = None\n",
    "    epsilon:float = None\n",
    "    epsilon_min: float = None\n",
    "    epsilon_decay: float = None\n",
    "    \n",
    "    # counter for updating model weight\n",
    "    learn_counter: int = 0\n",
    "    update_weight_on: int = 0\n",
    "    \n",
    "    def __init__(self, num_actions: int, max_replay: int, mini_batch_num: int, \n",
    "                 weight_update: int, epsilon: float, epsilon_min: float, \n",
    "                 epsilon_decay:float, gamma:float):\n",
    "        self.replay = ReplayMemory(max_replay, mini_batch_num)\n",
    "        self.eval_model, self.target_model = self.create_model()\n",
    "        self.num_actions = int(num_actions)\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.epsilon_min = epsilon_min\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "        self.update_weight_on = weight_update\n",
    "        \n",
    "    def create_model(self):\n",
    "        # Create your own model and return the sequential model.\n",
    "        # Need to watchout your input is need to be a state shape\n",
    "        # And your output need to be your action shape\n",
    "        model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Input(shape=(4,)),\n",
    "            tf.keras.layers.Dense(64, activation='relu'),\n",
    "            tf.keras.layers.Dense(32, activation='relu'),\n",
    "            tf.keras.layers.Dense(2, activation='linear'),\n",
    "        ])\n",
    "        \n",
    "        model.compile(optimizer = 'adam',\n",
    "                      loss = 'mean_squared_error',\n",
    "                      metrics= ['mse']\n",
    "                      )\n",
    "        \n",
    "        return model, model\n",
    "        \n",
    "    def store_memory(self, state, action, rewards, next_state, is_done):\n",
    "        if len(self.replay.main_memory) == self.replay.max_reply:\n",
    "            self.replay.main_memory.pop(0)\n",
    "        self.replay.main_memory.append([state, action, rewards, \n",
    "                                        next_state, is_done])\n",
    "        \n",
    "    def pick_action(self, state, epsilon = None):\n",
    "        if epsilon == None:\n",
    "            epsilon = self.epsilon\n",
    "        action = None\n",
    "        if random.random() > epsilon:\n",
    "            if type(state) != list:\n",
    "                state = state.tolist()\n",
    "            prediction = self.eval_model.predict([state])[0]\n",
    "            action = np.argmax(prediction)\n",
    "        else:\n",
    "            action = random.randint(0, self.num_actions - 1)\n",
    "            \n",
    "        return action\n",
    "    \n",
    "    def learn(self):\n",
    "        if len(self.replay.main_memory) < self.replay.num_batch:\n",
    "            return\n",
    "        samples = self.__sample_mini_batch__()\n",
    "        X_current = [x[0] for x in samples]\n",
    "        X_current = np.array(X_current)\n",
    "        X_next = [x[3] for x in samples]\n",
    "        X_next = np.array(X_next)\n",
    "        prediction = self.eval_model.predict(X_current)\n",
    "        target_prediction = self.target_model.predict(X_next)\n",
    "        for i in range(len(samples)):\n",
    "            if samples[i][4]: # if is_done\n",
    "                # For terminal next state\n",
    "                prediction[i][samples[i][1]] = samples[i][2]\n",
    "            else:\n",
    "                # For non-terminal next state\n",
    "                target = self.gamma * target_prediction[i][samples[i][1]]\n",
    "                prediction[i][samples[i][1]] = samples[i][2] + target\n",
    "                \n",
    "        X_train = [i[0] for i in samples]\n",
    "        X_train = np.array(X_train)\n",
    "        self.eval_model.fit(X_train, prediction, verbose=1, epochs=10)\n",
    "        print(self.epsilon)\n",
    "        if self.learn_counter % self.update_weight_on == 0:\n",
    "            self.__update_target_models__()\n",
    "        \n",
    "        # Post Learn\n",
    "        self.learn_counter += 1\n",
    "        epsilon_after_decay = self.epsilon * self.epsilon_decay\n",
    "        if  epsilon_after_decay < self.epsilon_min:\n",
    "            self.epsilon = self.epsilon_min\n",
    "        else:\n",
    "            self.epsilon = epsilon_after_decay\n",
    "            \n",
    "    def load_model(self,path:str):\n",
    "        self.target_model = tf.keras.models.load_model(path)\n",
    "        self.eval_model = tf.keras.models.load_model(path)\n",
    "        print(\"Model Loaded\")\n",
    "        \n",
    "    def save_model(self,path:str):\n",
    "        self.eval_model.save(path)\n",
    "        print(\"Model saved\")\n",
    "            \n",
    "    def __sample_mini_batch__(self):\n",
    "        return random.sample(self.replay.main_memory, self.replay.num_batch)\n",
    "\n",
    "    def __update_target_models__(self):\n",
    "        self.target_model.set_weights(self.eval_model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "class Environment:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.game = gym.make(\"CartPole-v1\")\n",
    "        action_space = self.game.action_space.n\n",
    "        self.agent = DeepQAgent(action_space, 10000, 2000, \n",
    "                                10, 1, 0.05, 0.9995, 0.95)\n",
    "        \n",
    "    def train(self, num_ep: int):\n",
    "        for i in range(1 , num_ep):\n",
    "            print(f\"Episodes {i}\")\n",
    "            state = self.game.reset()\n",
    "            while True:\n",
    "                self.game.render()\n",
    "                action = self.agent.pick_action(state)\n",
    "                state_next, reward, terminal, info = self.game.step(action)\n",
    "                self.agent.store_memory(state, action, reward, state_next, terminal)\n",
    "                state = state_next\n",
    "                if terminal:\n",
    "                    break\n",
    "                \n",
    "            self.agent.learn()\n",
    "                \n",
    "    def play(self):\n",
    "        while True:\n",
    "            state = self.game.reset()\n",
    "            while True:\n",
    "                self.game.render()\n",
    "                action = self.agent.pick_action(state, 0)\n",
    "                state, _, terminal, _ = self.game.step(action)\n",
    "                if terminal:\n",
    "                    break\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'int'>\n"
     ]
    }
   ],
   "source": [
    "envir = Environment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes 1\n",
      "Epoch 1/10\n",
      "63/63 [==============================] - 0s 790us/step - loss: 0.3211 - mse: 0.3211\n",
      "Epoch 2/10\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2618 - mse: 0.2618\n",
      "Epoch 3/10\n",
      "63/63 [==============================] - 0s 919us/step - loss: 0.2599 - mse: 0.2599\n",
      "Epoch 4/10\n",
      "63/63 [==============================] - 0s 774us/step - loss: 0.2598 - mse: 0.2598\n",
      "Epoch 5/10\n",
      "63/63 [==============================] - 0s 710us/step - loss: 0.2594 - mse: 0.2594\n",
      "Epoch 6/10\n",
      "63/63 [==============================] - 0s 806us/step - loss: 0.2599 - mse: 0.2599\n",
      "Epoch 7/10\n",
      "63/63 [==============================] - 0s 790us/step - loss: 0.2594 - mse: 0.2594\n",
      "Epoch 8/10\n",
      "63/63 [==============================] - 0s 710us/step - loss: 0.2591 - mse: 0.2591\n",
      "Epoch 9/10\n",
      "63/63 [==============================] - 0s 806us/step - loss: 0.2595 - mse: 0.2595\n",
      "Epoch 10/10\n",
      "63/63 [==============================] - 0s 742us/step - loss: 0.2594 - mse: 0.2594\n",
      "1\n",
      "Episodes 2\n",
      "Epoch 1/10\n",
      "63/63 [==============================] - 0s 742us/step - loss: 0.2627 - mse: 0.2627\n",
      "Epoch 2/10\n",
      "63/63 [==============================] - 0s 758us/step - loss: 0.2353 - mse: 0.2353\n",
      "Epoch 3/10\n",
      "63/63 [==============================] - 0s 694us/step - loss: 0.2348 - mse: 0.2348\n",
      "Epoch 4/10\n",
      "63/63 [==============================] - 0s 806us/step - loss: 0.2348 - mse: 0.2348\n",
      "Epoch 5/10\n",
      "63/63 [==============================] - 0s 694us/step - loss: 0.2349 - mse: 0.2349\n",
      "Epoch 6/10\n",
      "63/63 [==============================] - 0s 774us/step - loss: 0.2348 - mse: 0.2348\n",
      "Epoch 7/10\n",
      "63/63 [==============================] - 0s 758us/step - loss: 0.2349 - mse: 0.2349\n",
      "Epoch 8/10\n",
      "63/63 [==============================] - 0s 774us/step - loss: 0.2349 - mse: 0.2349\n",
      "Epoch 9/10\n",
      "63/63 [==============================] - 0s 758us/step - loss: 0.2346 - mse: 0.2346\n",
      "Epoch 10/10\n",
      "63/63 [==============================] - 0s 710us/step - loss: 0.2345 - mse: 0.2345\n",
      "0.9995\n",
      "Episodes 3\n",
      "Epoch 1/10\n",
      "63/63 [==============================] - 0s 839us/step - loss: 0.2406 - mse: 0.2406\n",
      "Epoch 2/10\n",
      "63/63 [==============================] - 0s 758us/step - loss: 0.2184 - mse: 0.2184\n",
      "Epoch 3/10\n",
      "63/63 [==============================] - 0s 758us/step - loss: 0.2185 - mse: 0.2185\n",
      "Epoch 4/10\n",
      "63/63 [==============================] - 0s 742us/step - loss: 0.2181 - mse: 0.2181\n",
      "Epoch 5/10\n",
      "63/63 [==============================] - 0s 806us/step - loss: 0.2178 - mse: 0.2178\n",
      "Epoch 6/10\n",
      "63/63 [==============================] - 0s 823us/step - loss: 0.2179 - mse: 0.2179\n",
      "Epoch 7/10\n",
      "63/63 [==============================] - 0s 742us/step - loss: 0.2172 - mse: 0.2172\n",
      "Epoch 8/10\n",
      "63/63 [==============================] - 0s 726us/step - loss: 0.2180 - mse: 0.2180\n",
      "Epoch 9/10\n",
      "63/63 [==============================] - 0s 855us/step - loss: 0.2171 - mse: 0.2171\n",
      "Epoch 10/10\n",
      "63/63 [==============================] - 0s 694us/step - loss: 0.2172 - mse: 0.2172\n",
      "0.9990002500000001\n",
      "Episodes 4\n",
      "Epoch 1/10\n",
      "63/63 [==============================] - 0s 758us/step - loss: 0.2280 - mse: 0.2280\n",
      "Epoch 2/10\n",
      "63/63 [==============================] - 0s 742us/step - loss: 0.2068 - mse: 0.2068\n",
      "Epoch 3/10\n",
      "63/63 [==============================] - 0s 709us/step - loss: 0.2067 - mse: 0.2067\n",
      "Epoch 4/10\n",
      "63/63 [==============================] - 0s 758us/step - loss: 0.2062 - mse: 0.2062\n",
      "Epoch 5/10\n",
      "63/63 [==============================] - 0s 742us/step - loss: 0.2052 - mse: 0.2052\n",
      "Epoch 6/10\n",
      "63/63 [==============================] - 0s 726us/step - loss: 0.2051 - mse: 0.2051\n",
      "Epoch 7/10\n",
      "63/63 [==============================] - 0s 742us/step - loss: 0.2051 - mse: 0.2051\n",
      "Epoch 8/10\n",
      "63/63 [==============================] - 0s 790us/step - loss: 0.2049 - mse: 0.2049\n",
      "Epoch 9/10\n",
      "63/63 [==============================] - 0s 774us/step - loss: 0.2044 - mse: 0.2044\n",
      "Epoch 10/10\n",
      "63/63 [==============================] - 0s 855us/step - loss: 0.2040 - mse: 0.2040\n",
      "0.9985007498750001\n",
      "Episodes 5\n",
      "Epoch 1/10\n",
      "63/63 [==============================] - 0s 742us/step - loss: 0.2093 - mse: 0.2093\n",
      "Epoch 2/10\n",
      "63/63 [==============================] - 0s 774us/step - loss: 0.1960 - mse: 0.1960\n",
      "Epoch 3/10\n",
      "63/63 [==============================] - 0s 710us/step - loss: 0.1956 - mse: 0.1956\n",
      "Epoch 4/10\n",
      "63/63 [==============================] - 0s 774us/step - loss: 0.1947 - mse: 0.1947\n",
      "Epoch 5/10\n",
      "63/63 [==============================] - 0s 742us/step - loss: 0.1942 - mse: 0.1942\n",
      "Epoch 6/10\n",
      "63/63 [==============================] - 0s 726us/step - loss: 0.1924 - mse: 0.1924\n",
      "Epoch 7/10\n",
      "63/63 [==============================] - 0s 790us/step - loss: 0.1921 - mse: 0.1921\n",
      "Epoch 8/10\n",
      "63/63 [==============================] - 0s 758us/step - loss: 0.1918 - mse: 0.1918\n",
      "Epoch 9/10\n",
      "63/63 [==============================] - 0s 710us/step - loss: 0.1917 - mse: 0.1917\n",
      "Epoch 10/10\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1921 - mse: 0.1921\n",
      "0.9980014995000627\n",
      "Episodes 6\n",
      "Epoch 1/10\n",
      "63/63 [==============================] - 0s 774us/step - loss: 0.2008 - mse: 0.2008\n",
      "Epoch 2/10\n",
      "63/63 [==============================] - 0s 758us/step - loss: 0.1835 - mse: 0.1835\n",
      "Epoch 3/10\n",
      "63/63 [==============================] - 0s 790us/step - loss: 0.1827 - mse: 0.1827\n",
      "Epoch 4/10\n",
      "63/63 [==============================] - 0s 758us/step - loss: 0.1813 - mse: 0.1813\n",
      "Epoch 5/10\n",
      "63/63 [==============================] - 0s 758us/step - loss: 0.1813 - mse: 0.1813\n",
      "Epoch 6/10\n",
      "63/63 [==============================] - 0s 774us/step - loss: 0.1809 - mse: 0.1809\n",
      "Epoch 7/10\n",
      "63/63 [==============================] - 0s 758us/step - loss: 0.1807 - mse: 0.1807\n",
      "Epoch 8/10\n",
      "63/63 [==============================] - 0s 790us/step - loss: 0.1795 - mse: 0.1795\n",
      "Epoch 9/10\n",
      "63/63 [==============================] - 0s 758us/step - loss: 0.1793 - mse: 0.1793\n",
      "Epoch 10/10\n",
      "63/63 [==============================] - 0s 758us/step - loss: 0.1797 - mse: 0.1797\n",
      "0.9975024987503127\n",
      "Episodes 7\n",
      "Epoch 1/10\n",
      "63/63 [==============================] - 0s 790us/step - loss: 0.1795 - mse: 0.1795\n",
      "Epoch 2/10\n",
      "63/63 [==============================] - 0s 790us/step - loss: 0.1670 - mse: 0.1670\n",
      "Epoch 3/10\n",
      "63/63 [==============================] - 0s 742us/step - loss: 0.1637 - mse: 0.1637\n",
      "Epoch 4/10\n",
      "63/63 [==============================] - 0s 742us/step - loss: 0.1630 - mse: 0.1630\n",
      "Epoch 5/10\n",
      "63/63 [==============================] - 0s 742us/step - loss: 0.1621 - mse: 0.1621\n",
      "Epoch 6/10\n",
      "63/63 [==============================] - 0s 742us/step - loss: 0.1630 - mse: 0.1630\n",
      "Epoch 7/10\n",
      "63/63 [==============================] - 0s 742us/step - loss: 0.1622 - mse: 0.1622\n",
      "Epoch 8/10\n",
      "63/63 [==============================] - 0s 935us/step - loss: 0.1623 - mse: 0.1623\n",
      "Epoch 9/10\n",
      "63/63 [==============================] - 0s 774us/step - loss: 0.1612 - mse: 0.1612\n",
      "Epoch 10/10\n",
      "63/63 [==============================] - 0s 710us/step - loss: 0.1612 - mse: 0.1612\n",
      "0.9970037475009376\n",
      "Episodes 8\n",
      "Epoch 1/10\n",
      "63/63 [==============================] - 0s 710us/step - loss: 0.1655 - mse: 0.1655\n",
      "Epoch 2/10\n",
      "63/63 [==============================] - 0s 806us/step - loss: 0.1507 - mse: 0.1507\n",
      "Epoch 3/10\n",
      "63/63 [==============================] - 0s 710us/step - loss: 0.1496 - mse: 0.1496\n",
      "Epoch 4/10\n",
      "63/63 [==============================] - 0s 790us/step - loss: 0.1495 - mse: 0.1495\n",
      "Epoch 5/10\n",
      "63/63 [==============================] - 0s 726us/step - loss: 0.1504 - mse: 0.1504\n",
      "Epoch 6/10\n",
      "63/63 [==============================] - 0s 790us/step - loss: 0.1478 - mse: 0.1478\n",
      "Epoch 7/10\n",
      "63/63 [==============================] - 0s 758us/step - loss: 0.1480 - mse: 0.1480\n",
      "Epoch 8/10\n",
      "63/63 [==============================] - 0s 710us/step - loss: 0.1476 - mse: 0.1476\n",
      "Epoch 9/10\n",
      "63/63 [==============================] - 0s 726us/step - loss: 0.1467 - mse: 0.1467\n",
      "Epoch 10/10\n",
      "63/63 [==============================] - 0s 790us/step - loss: 0.1472 - mse: 0.1472\n",
      "0.9965052456271871\n",
      "Episodes 9\n",
      "Epoch 1/10\n",
      "63/63 [==============================] - 0s 742us/step - loss: 0.1464 - mse: 0.1464\n",
      "Epoch 2/10\n",
      "63/63 [==============================] - 0s 742us/step - loss: 0.1342 - mse: 0.1342\n",
      "Epoch 3/10\n",
      "63/63 [==============================] - 0s 726us/step - loss: 0.1344 - mse: 0.1344\n",
      "Epoch 4/10\n",
      "63/63 [==============================] - 0s 726us/step - loss: 0.1339 - mse: 0.1339\n",
      "Epoch 5/10\n",
      "63/63 [==============================] - 0s 742us/step - loss: 0.1332 - mse: 0.1332\n",
      "Epoch 6/10\n",
      "63/63 [==============================] - 0s 790us/step - loss: 0.1334 - mse: 0.1334\n",
      "Epoch 7/10\n",
      "63/63 [==============================] - 0s 694us/step - loss: 0.1319 - mse: 0.1319\n",
      "Epoch 8/10\n",
      "63/63 [==============================] - 0s 710us/step - loss: 0.1328 - mse: 0.1328\n",
      "Epoch 9/10\n",
      "63/63 [==============================] - 0s 774us/step - loss: 0.1325 - mse: 0.1325\n",
      "Epoch 10/10\n",
      "63/63 [==============================] - 0s 742us/step - loss: 0.1322 - mse: 0.1322\n",
      "0.9960069930043736\n",
      "Episodes 10\n",
      "Epoch 1/10\n",
      "63/63 [==============================] - 0s 758us/step - loss: 0.1346 - mse: 0.1346\n",
      "Epoch 2/10\n",
      "63/63 [==============================] - 0s 790us/step - loss: 0.1238 - mse: 0.1238\n",
      "Epoch 3/10\n",
      "63/63 [==============================] - 0s 806us/step - loss: 0.1238 - mse: 0.1238\n",
      "Epoch 4/10\n",
      "63/63 [==============================] - 0s 742us/step - loss: 0.1229 - mse: 0.1229\n",
      "Epoch 5/10\n",
      "63/63 [==============================] - 0s 758us/step - loss: 0.1227 - mse: 0.1227\n",
      "Epoch 6/10\n",
      "63/63 [==============================] - 0s 790us/step - loss: 0.1226 - mse: 0.1226\n",
      "Epoch 7/10\n",
      "63/63 [==============================] - 0s 742us/step - loss: 0.1230 - mse: 0.1230\n",
      "Epoch 8/10\n",
      "63/63 [==============================] - 0s 742us/step - loss: 0.1221 - mse: 0.1221\n",
      "Epoch 9/10\n",
      "63/63 [==============================] - 0s 710us/step - loss: 0.1223 - mse: 0.1223\n",
      "Epoch 10/10\n",
      "63/63 [==============================] - 0s 758us/step - loss: 0.1211 - mse: 0.1211\n",
      "0.9955089895078715\n",
      "Episodes 11\n",
      "Epoch 1/10\n",
      "63/63 [==============================] - 0s 758us/step - loss: 0.1221 - mse: 0.1221\n",
      "Epoch 2/10\n",
      "63/63 [==============================] - 0s 758us/step - loss: 0.1138 - mse: 0.1138\n",
      "Epoch 3/10\n",
      "63/63 [==============================] - 0s 726us/step - loss: 0.1131 - mse: 0.1131\n",
      "Epoch 4/10\n",
      "63/63 [==============================] - 0s 710us/step - loss: 0.1144 - mse: 0.1144\n",
      "Epoch 5/10\n",
      "63/63 [==============================] - 0s 758us/step - loss: 0.1138 - mse: 0.1138\n",
      "Epoch 6/10\n",
      "63/63 [==============================] - 0s 726us/step - loss: 0.1123 - mse: 0.1123\n",
      "Epoch 7/10\n",
      "63/63 [==============================] - 0s 693us/step - loss: 0.1128 - mse: 0.1128\n",
      "Epoch 8/10\n",
      "63/63 [==============================] - 0s 726us/step - loss: 0.1126 - mse: 0.1126\n",
      "Epoch 9/10\n",
      "63/63 [==============================] - 0s 726us/step - loss: 0.1118 - mse: 0.1118\n",
      "Epoch 10/10\n",
      "63/63 [==============================] - 0s 726us/step - loss: 0.1105 - mse: 0.1105\n",
      "0.9950112350131176\n",
      "Episodes 12\n",
      "Epoch 1/10\n",
      "63/63 [==============================] - 0s 694us/step - loss: 0.1161 - mse: 0.1161\n",
      "Epoch 2/10\n",
      "63/63 [==============================] - 0s 774us/step - loss: 0.1052 - mse: 0.1052\n",
      "Epoch 3/10\n",
      "63/63 [==============================] - 0s 823us/step - loss: 0.1048 - mse: 0.1048\n",
      "Epoch 4/10\n",
      "63/63 [==============================] - 0s 871us/step - loss: 0.1037 - mse: 0.1037\n",
      "Epoch 5/10\n",
      "63/63 [==============================] - 0s 742us/step - loss: 0.1028 - mse: 0.1028\n",
      "Epoch 6/10\n",
      "63/63 [==============================] - 0s 726us/step - loss: 0.1022 - mse: 0.1022\n",
      "Epoch 7/10\n",
      "63/63 [==============================] - 0s 774us/step - loss: 0.1034 - mse: 0.1034\n",
      "Epoch 8/10\n",
      "63/63 [==============================] - 0s 806us/step - loss: 0.1017 - mse: 0.1017\n",
      "Epoch 9/10\n",
      "63/63 [==============================] - 0s 710us/step - loss: 0.1030 - mse: 0.1030\n",
      "Epoch 10/10\n",
      "63/63 [==============================] - 0s 710us/step - loss: 0.1011 - mse: 0.1011\n",
      "0.9945137293956111\n",
      "Episodes 13\n",
      "Epoch 1/10\n",
      "63/63 [==============================] - 0s 903us/step - loss: 0.1018 - mse: 0.1018\n",
      "Epoch 2/10\n",
      "63/63 [==============================] - 0s 823us/step - loss: 0.0956 - mse: 0.0956\n",
      "Epoch 3/10\n",
      "63/63 [==============================] - 0s 871us/step - loss: 0.0949 - mse: 0.0949\n",
      "Epoch 4/10\n",
      "63/63 [==============================] - 0s 774us/step - loss: 0.0966 - mse: 0.0966\n",
      "Epoch 5/10\n",
      "63/63 [==============================] - 0s 742us/step - loss: 0.0950 - mse: 0.0950\n",
      "Epoch 6/10\n",
      "63/63 [==============================] - 0s 774us/step - loss: 0.0949 - mse: 0.0949\n",
      "Epoch 7/10\n",
      "63/63 [==============================] - 0s 726us/step - loss: 0.0926 - mse: 0.0926\n",
      "Epoch 8/10\n",
      "63/63 [==============================] - 0s 758us/step - loss: 0.0946 - mse: 0.0946\n",
      "Epoch 9/10\n",
      "63/63 [==============================] - 0s 710us/step - loss: 0.0940 - mse: 0.0940\n",
      "Epoch 10/10\n",
      "63/63 [==============================] - 0s 726us/step - loss: 0.0933 - mse: 0.0933\n",
      "0.9940164725309134\n",
      "Episodes 14\n"
     ]
    }
   ],
   "source": [
    "envir.train(30000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved\n"
     ]
    }
   ],
   "source": [
    "envir.agent.save_model(\"./model/cart-pole.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "139722cea5c49de78fb043fac3809b8c30f4cb03279f633027f064fb572eb5e6"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
